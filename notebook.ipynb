{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial-setup",
   "metadata": {},
   "source": [
    "#  H·ªá Th·ªëng G·ª£i √ù Ng√†nh H·ªçc - Hu·∫•n Luy·ªán M√¥ H√¨nh\n",
    "## Training v·ªõi d·ªØ li·ªáu hi·ªán c√≥ c·ªßa b·∫°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from deep_translator import GoogleTranslator\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ ƒê√£ import t·∫•t c·∫£ th∆∞ vi·ªán c·∫ßn thi·∫øt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "check-files",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 1: Ki·ªÉm tra t·ªáp d·ªØ li·ªáu c·ªßa b·∫°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-data-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_files():\n",
    "    \"\"\"Ki·ªÉm tra xem c√°c t·ªáp d·ªØ li·ªáu c√≥ t·ªìn t·∫°i kh√¥ng\"\"\"\n",
    "    print(\"üîç KI·ªÇM TRA T·ªÜP D·ªÆ LI·ªÜU...\")\n",
    "    \n",
    "    # Ki·ªÉm tra c√°c file trong th∆∞ m·ª•c data\n",
    "    data_files = []\n",
    "    if os.path.exists('data'):\n",
    "        print(\"üìÅ KI·ªÇM TRA TH∆Ø M·ª§C 'data':\")\n",
    "        for file in os.listdir('data'):\n",
    "            file_path = os.path.join('data', file)\n",
    "            file_size = os.path.getsize(file_path) / 1024\n",
    "            print(f\"   ‚úÖ {file}: {file_size:.1f} KB\")\n",
    "            data_files.append(file_path)\n",
    "    else:\n",
    "        print(\"‚ùå Th∆∞ m·ª•c 'data' kh√¥ng t·ªìn t·∫°i\")\n",
    "    \n",
    "    # Ki·ªÉm tra c√°c file trong th∆∞ m·ª•c g·ªëc\n",
    "    print(\"\\nüìÅ KI·ªÇM TRA TH∆Ø M·ª§C G·ªêC:\")\n",
    "    root_files = [\n",
    "        'final_majors_data.csv',\n",
    "        'tfidf_vectorizer.pkl',\n",
    "        'notebook.ipynb'\n",
    "    ]\n",
    "    \n",
    "    for file in root_files:\n",
    "        if os.path.exists(file):\n",
    "            file_size = os.path.getsize(file) / 1024\n",
    "            print(f\"   ‚úÖ {file}: {file_size:.1f} KB\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {file}: KH√îNG T√åM TH·∫§Y\")\n",
    "    \n",
    "    return data_files\n",
    "\n",
    "# Ki·ªÉm tra t·ªáp\n",
    "available_files = check_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-existing-model",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 2: Ki·ªÉm tra m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-existing-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existing_model():\n",
    "    \"\"\"Ki·ªÉm tra xem ƒë√£ c√≥ m√¥ h√¨nh hu·∫•n luy·ªán ch∆∞a\"\"\"\n",
    "    print(\"\\n KI·ªÇM TRA M√î H√åNH ƒê√É HU·∫§N LUY·ªÜN (VIETNAMESE)...\")\n",
    "    \n",
    "    if os.path.exists('tfidf_vectorizer_vi.pkl'):\n",
    "        print(\"‚úÖ T√¨m th·∫•y m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán: tfidf_vectorizer_vi.pkl\")\n",
    "        \n",
    "        # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω\n",
    "        if os.path.exists('final_majors_data_vi.csv'):\n",
    "            df = pd.read_csv('final_majors_data_vi.csv')\n",
    "            print(f\" D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω: {len(df)} ng√†nh h·ªçc (ti·∫øng Vi·ªát)\")\n",
    "            print(\" H·ªá th·ªëng ƒë√£ S·∫¥N S√ÄNG ƒë·ªÉ s·ª≠ d·ª•ng!\")\n",
    "            return True\n",
    "    else:\n",
    "        print(\"‚ùå Ch∆∞a c√≥ m√¥ h√¨nh ti·∫øng Vi·ªát, ti·∫øn h√†nh hu·∫•n luy·ªán m·ªõi...\")\n",
    "        return False\n",
    "\n",
    "model_exists = check_existing_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-new-model",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 3: Hu·∫•n luy·ªán m√¥ h√¨nh m·ªõi (n·∫øu c·∫ßn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-new-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_model():\n",
    "    \"\"\"Hu·∫•n luy·ªán m√¥ h√¨nh m·ªõi n·∫øu ch∆∞a c√≥\"\"\"\n",
    "    print(\"\\n B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN M√î H√åNH M·ªöI...\")\n",
    "    \n",
    "    # T·∫£i d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c data\n",
    "    try:\n",
    "        df_coursera = pd.read_csv('data/coursera_course_dataset_v2_no_null.csv')\n",
    "        df_rankings = pd.read_csv('data/cwurData.csv')\n",
    "        print(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng t·ª´ th∆∞ m·ª•c data\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "    print(\" ƒêang chu·∫©n b·ªã d·ªØ li·ªáu...\")\n",
    "    \n",
    "    # ƒê·ªïi t√™n c·ªôt\n",
    "    df_coursera = df_coursera.rename(columns={\n",
    "        'Title': 'major_name',\n",
    "        'Organization': 'university_name', \n",
    "        'Skills': 'major_description'\n",
    "    })\n",
    "    \n",
    "    # T·∫°o DataFrame m·ªõi\n",
    "    final_courses_df = df_coursera[['major_name', 'university_name', 'major_description']].copy()\n",
    "    final_courses_df.dropna(subset=['major_description'], inplace=True)\n",
    "    final_courses_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Chu·∫©n h√≥a t√™n\n",
    "    df_rankings['institution'] = df_rankings['institution'].str.lower()\n",
    "    final_courses_df['university_name'] = final_courses_df['university_name'].str.lower()\n",
    "    \n",
    "    # H·ª£p nh·∫•t d·ªØ li·ªáu\n",
    "    df_rankings_simple = df_rankings[['institution', 'country', 'score']]\n",
    "    master_df = pd.merge(\n",
    "        final_courses_df,\n",
    "        df_rankings_simple,\n",
    "        left_on='university_name',\n",
    "        right_on='institution',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # X·ª≠ l√Ω gi√° tr·ªã thi·∫øu\n",
    "    master_df['score'] = master_df['score'].fillna(master_df['score'].mean())\n",
    "    master_df['country'] = master_df['country'].fillna('Unknown')\n",
    "    \n",
    "    # T·∫°o DataFrame cu·ªëi c√πng\n",
    "    final_df = master_df[['major_name', 'major_description', 'university_name', 'country', 'score']]\n",
    "    final_df = final_df.rename(columns={'score': 'university_score'})\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üìà ƒê√£ x·ª≠ l√Ω xong: {len(final_df)} ng√†nh h·ªçc\")\n",
    "    \n",
    "    # Hu·∫•n luy·ªán TF-IDF\n",
    "    print(\" ƒêang hu·∫•n luy·ªán m√¥ h√¨nh TF-IDF...\")\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "    major_vectors = vectorizer.fit_transform(final_df['major_description'])\n",
    "    \n",
    "    print(\"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!\")\n",
    "    print(f\" K√≠ch th∆∞·ªõc ma tr·∫≠n: {major_vectors.shape}\")\n",
    "    \n",
    "    return vectorizer, final_df\n",
    "\n",
    "# Ch·ªâ hu·∫•n luy·ªán n·∫øu ch∆∞a c√≥ model\n",
    "if not model_exists:\n",
    "    vectorizer, final_df = train_new_model()\n",
    "else:\n",
    "    # Load model v√† data hi·ªán c√≥\n",
    "    vectorizer = joblib.load('tfidf_vectorizer_vi.pkl')\n",
    "    final_df = pd.read_csv('final_majors_data_vi.csv')\n",
    "    print(\"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh v√† d·ªØ li·ªáu ti·∫øng Vi·ªát hi·ªán c√≥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-model",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 4: L∆∞u m√¥ h√¨nh (n·∫øu hu·∫•n luy·ªán m·ªõi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model-if-new",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(vectorizer, dataframe):\n",
    "    \"\"\"L∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\"\"\"\n",
    "    print(\"\\n ƒêANG L∆ØU M√î H√åNH...\")\n",
    "    \n",
    "    # L∆∞u vectorizer\n",
    "    joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "    \n",
    "    # L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω\n",
    "    dataframe.to_csv('final_majors_data.csv', index=False)\n",
    "    \n",
    "    # L∆∞u metadata\n",
    "    metadata = {\n",
    "        'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'num_courses': len(dataframe),\n",
    "        'num_universities': dataframe['university_name'].nunique(),\n",
    "        'num_features': vectorizer.get_feature_names_out().shape[0]\n",
    "    }\n",
    "    joblib.dump(metadata, 'model_metadata.pkl')\n",
    "    \n",
    "    print(\"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh th√†nh c√¥ng!\")\n",
    "    print(f\"üìÅ C√°c t·ªáp ƒë√£ l∆∞u:\")\n",
    "    print(f\"   - tfidf_vectorizer.pkl (M√¥ h√¨nh TF-IDF)\")\n",
    "    print(f\"   - final_majors_data.csv (D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω)\")\n",
    "    print(f\"   - model_metadata.pkl (Th√¥ng tin hu·∫•n luy·ªán)\")\n",
    "\n",
    "# L∆∞u model n·∫øu v·ª´a hu·∫•n luy·ªán m·ªõi\n",
    "if not model_exists and 'vectorizer' in locals() and 'final_df' in locals():\n",
    "    save_trained_model(vectorizer, final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-system",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 5: Ki·ªÉm tra h·ªá th·ªëng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-recommendation-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recommendation_system():\n",
    "    \"\"\"Ki·ªÉm tra h·ªá th·ªëng g·ª£i √Ω\"\"\"\n",
    "    print(\"\\n KI·ªÇM TRA H·ªÜ TH·ªêNG G·ª¢I √ù...\")\n",
    "    \n",
    "    # Load model v√† data\n",
    "    vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "    final_df = pd.read_csv('final_majors_data.csv')\n",
    "    \n",
    "    # Vector h√≥a d·ªØ li·ªáu\n",
    "    major_vectors = vectorizer.transform(final_df['major_description'])\n",
    "    \n",
    "    # H√†m g·ª£i √Ω\n",
    "    def get_recommendations(user_interest, min_score=60, top_n=3):\n",
    "        # D·ªãch sang ti·∫øng Anh n·∫øu c·∫ßn\n",
    "        if any(char in user_interest for char in '√†√°√¢√£√®√©√™√¨√≠√≤√≥√¥√µ√π√∫√Ω·ª≥·ªπ·ª∑·ªµ'):\n",
    "            try:\n",
    "                translator = GoogleTranslator(source='vi', target='en')\n",
    "                user_interest = translator.translate(user_interest)\n",
    "                print(f\"üåê ƒê√£ d·ªãch sang: '{user_interest}'\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # L·ªçc theo ƒëi·ªÉm\n",
    "        filtered_df = final_df[final_df['university_score'] >= min_score]\n",
    "        \n",
    "        if filtered_df.empty:\n",
    "            print(\"‚ùå Kh√¥ng c√≥ ng√†nh h·ªçc n√†o ph√π h·ª£p\")\n",
    "            return None\n",
    "        \n",
    "        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng\n",
    "        user_vector = vectorizer.transform([user_interest])\n",
    "        filtered_indices = filtered_df.index\n",
    "        similarities = cosine_similarity(user_vector, major_vectors[filtered_indices])\n",
    "        \n",
    "        # Th√™m ƒëi·ªÉm v√† s·∫Øp x·∫øp\n",
    "        filtered_df = filtered_df.copy()\n",
    "        filtered_df['similarity'] = similarities[0]\n",
    "        recommendations = filtered_df.nlargest(top_n, 'similarity')\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        (\"data science\", 70, \"Khoa h·ªçc d·ªØ li·ªáu\"),\n",
    "        (\"machine learning\", 65, \"H·ªçc m√°y\"),\n",
    "        (\"business management\", 60, \"Qu·∫£n tr·ªã kinh doanh\")\n",
    "    ]\n",
    "    \n",
    "    for interest, score, description in test_cases:\n",
    "        print(f\"\\nüîç T√¨m ki·∫øm: {description} (ƒëi·ªÉm ‚â• {score})\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        results = get_recommendations(interest, score, 2)\n",
    "        \n",
    "        if results is not None and not results.empty:\n",
    "            for idx, (_, row) in enumerate(results.iterrows(), 1):\n",
    "                print(f\"{idx}. üéì {row['major_name']}\")\n",
    "                print(f\"   üè´ {row['university_name'].title()}\")\n",
    "                print(f\"   ‚≠ê ƒêi·ªÉm: {row['university_score']:.1f}\")\n",
    "                print(f\"   üí´ ƒê·ªô ph√π h·ª£p: {row['similarity']:.3f}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"   Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£\")\n",
    "    \n",
    "    print(\"‚úÖ H·ªá th·ªëng ho·∫°t ƒë·ªông t·ªët!\")\n",
    "\n",
    "# Ch·∫°y ki·ªÉm tra\n",
    "test_recommendation_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-summary",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 6: T·ªïng k·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary():\n",
    "    \"\"\"Hi·ªÉn th·ªã t·ªïng k·∫øt h·ªá th·ªëng\"\"\"\n",
    "    print(\"\\n\" + \"üéØ\" * 30)\n",
    "    print(\"T·ªîNG K·∫æT H·ªÜ TH·ªêNG G·ª¢I √ù\")\n",
    "    print(\"üéØ\" * 30)\n",
    "    \n",
    "    # Load metadata\n",
    "    if os.path.exists('model_metadata.pkl'):\n",
    "        metadata = joblib.load('model_metadata.pkl')\n",
    "        print(\"üìä TH√îNG TIN HU·∫§N LUY·ªÜN:\")\n",
    "        print(f\"   ‚Ä¢ Th·ªùi gian: {metadata['training_date']}\")\n",
    "        print(f\"   ‚Ä¢ S·ªë ng√†nh h·ªçc: {metadata['num_courses']}\")\n",
    "        print(f\"   ‚Ä¢ S·ªë tr∆∞·ªùng: {metadata['num_universities']}\")\n",
    "        print(f\"   ‚Ä¢ S·ªë t·ª´ v·ª±ng: {metadata['num_features']}\")\n",
    "    \n",
    "    # Hi·ªÉn th·ªã d·ªØ li·ªáu\n",
    "    df = pd.read_csv('final_majors_data.csv')\n",
    "    print(f\"\\nüìà TH·ªêNG K√ä D·ªÆ LI·ªÜU:\")\n",
    "    print(f\"   ‚Ä¢ T·ªïng s·ªë ng√†nh: {len(df)}\")\n",
    "    print(f\"   ‚Ä¢ S·ªë tr∆∞·ªùng duy nh·∫•t: {df['university_name'].nunique()}\")\n",
    "    print(f\"   ‚Ä¢ ƒêi·ªÉm tr∆∞·ªùng trung b√¨nh: {df['university_score'].mean():.1f}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ H·ªÜ TH·ªêNG ƒê√É S·∫¥N S√ÄNG!\")\n",
    "    print(\"üí° S·ª≠ d·ª•ng h√†m get_recommendations() ƒë·ªÉ nh·∫≠n g·ª£i √Ω\")\n",
    "\n",
    "# Hi·ªÉn th·ªã t·ªïng k·∫øt\n",
    "show_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-example",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 7: H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usage-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìñ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\"\"\n",
    "ƒê·ªÉ s·ª≠ d·ª•ng h·ªá th·ªëng g·ª£i √Ω, copy h√†m sau:\n",
    "\n",
    "def get_course_recommendations(your_interest, min_score=60, top_n=5):\n",
    "    # Load model\n",
    "    vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "    final_df = pd.read_csv('final_majors_data.csv')\n",
    "    major_vectors = vectorizer.transform(final_df['major_description'])\n",
    "    \n",
    "    # D·ªãch n·∫øu l√† ti·∫øng Vi·ªát\n",
    "    if any(char in your_interest for char in '√†√°√¢√£√®√©√™√¨√≠√≤√≥√¥√µ√π√∫√Ω·ª≥·ªπ·ª∑·ªµ'):\n",
    "        translator = GoogleTranslator(source='vi', target='en')\n",
    "        your_interest = translator.translate(your_interest)\n",
    "    \n",
    "    # L·ªçc v√† t√≠nh to√°n\n",
    "    filtered_df = final_df[final_df['university_score'] >= min_score]\n",
    "    user_vector = vectorizer.transform([your_interest])\n",
    "    filtered_indices = filtered_df.index\n",
    "    similarities = cosine_similarity(user_vector, major_vectors[filter_indices])\n",
    "    \n",
    "    filtered_df = filtered_df.copy()\n",
    "    filtered_df['similarity'] = similarities[0]\n",
    "    return filtered_df.nlargest(top_n, 'similarity')\n",
    "\n",
    "# V√≠ d·ª• s·ª≠ d·ª•ng:\n",
    "results = get_course_recommendations(\n",
    "    \"khoa h·ªçc d·ªØ li·ªáu v√† tr√≠ tu·ªá nh√¢n t·∫°o\", \n",
    "    min_score=70, \n",
    "    top_n=3\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n HU·∫§N LUY·ªÜN HO√ÄN T·∫§T! H·ªá th·ªëng ƒë√£ s·∫µn s√†ng.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}