{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74de0134",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-17T14:53:11.827219Z",
     "iopub.status.busy": "2025-10-17T14:53:11.826232Z",
     "iopub.status.idle": "2025-10-17T14:53:13.713873Z",
     "shell.execute_reply": "2025-10-17T14:53:13.712900Z"
    },
    "papermill": {
     "duration": 1.893269,
     "end_time": "2025-10-17T14:53:13.715524",
     "exception": false,
     "start_time": "2025-10-17T14:53:11.822255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tải dữ liệu thành công!\n",
      "\n",
      "🎉 Dữ liệu đã sẵn sàng cho Bước 2!\n",
      "-----------------------------------------\n",
      "5 dòng dữ liệu đầu tiên:\n",
      "                              major_name  \\\n",
      "0                   Google Cybersecurity   \n",
      "1                  Google Data Analytics   \n",
      "2             Google Project Management:   \n",
      "3                       IBM Data Science   \n",
      "4  Google Digital Marketing & E-commerce   \n",
      "\n",
      "                                   major_description university_name  country  \\\n",
      "0   Network Security, Python Programming, Linux, ...          google  Unknown   \n",
      "1   Data Analysis, R Programming, SQL, Business C...          google  Unknown   \n",
      "2   Project Management, Strategy and Operations, ...          google  Unknown   \n",
      "3   Python Programming, Data Science, Machine Lea...             ibm  Unknown   \n",
      "4   Digital Marketing, Marketing, Marketing Manag...          google  Unknown   \n",
      "\n",
      "   university_score  \n",
      "0         62.399382  \n",
      "1         62.399382  \n",
      "2         62.399382  \n",
      "3         62.399382  \n",
      "4         62.399382  \n",
      "\n",
      "Kích thước dữ liệu cuối cùng: 1084 dòng và 5 cột.\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Tải 2 bộ dữ liệu chính ---\n",
    "# Dùng try-except để bắt lỗi FileNotFoundError một cách tường minh\n",
    "try:\n",
    "    df_rankings = pd.read_csv('/kaggle/input/world-university-rankings/cwurData.csv')\n",
    "    df_coursera = pd.read_csv('/kaggle/input/coursera-course-data/coursera_course_dataset_v2_no_null.csv')\n",
    "    print(\"✅ Tải dữ liệu thành công!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ LỖI: Không tìm thấy tệp. Vui lòng kiểm tra lại đường dẫn trong phần 'Data'.\")\n",
    "    print(f\"Chi tiết lỗi: {e}\")\n",
    "\n",
    "\n",
    "# --- 2. Chuẩn hóa cột cho bộ dữ liệu Coursera ---\n",
    "# Đổi tên các cột gốc ('Title', 'Organization', 'Skills') thành các tên chuẩn ('major_name', 'university_name', 'major_description')\n",
    "df_coursera = df_coursera.rename(columns={\n",
    "    'Title': 'major_name',\n",
    "    'Organization': 'university_name',\n",
    "    'Skills': 'major_description'\n",
    "})\n",
    "\n",
    "# Tạo một DataFrame mới, độc lập bằng .copy() để tránh cảnh báo SettingWithCopyWarning\n",
    "final_courses_df = df_coursera[['major_name', 'university_name', 'major_description']].copy()\n",
    "\n",
    "# Làm sạch dữ liệu trên DataFrame mới\n",
    "final_courses_df.dropna(subset=['major_description'], inplace=True)\n",
    "final_courses_df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# --- 3. Hợp nhất dữ liệu khóa học với dữ liệu xếp hạng ---\n",
    "# Chuẩn hóa tên trường về chữ thường để khớp (merge)\n",
    "df_rankings['institution'] = df_rankings['institution'].str.lower()\n",
    "final_courses_df['university_name'] = final_courses_df['university_name'].str.lower()\n",
    "\n",
    "# Chỉ lấy các cột cần thiết từ bảng xếp hạng\n",
    "df_rankings_simple = df_rankings[['institution', 'country', 'score']]\n",
    "\n",
    "# Hợp nhất hai DataFrame\n",
    "master_df = pd.merge(\n",
    "    final_courses_df,\n",
    "    df_rankings_simple,\n",
    "    left_on='university_name',\n",
    "    right_on='institution',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- 4. Xử lý các giá trị bị thiếu sau khi hợp nhất ---\n",
    "# Thay vì dùng inplace=True, gán lại giá trị một cách trực tiếp để an toàn hơn\n",
    "master_df['score'] = master_df['score'].fillna(master_df['score'].mean())\n",
    "master_df['country'] = master_df['country'].fillna('Unknown')\n",
    "\n",
    "# Đổi tên cột 'score' thành 'university_score' cho rõ ràng\n",
    "master_df = master_df.rename(columns={'score': 'university_score'})\n",
    "\n",
    "\n",
    "# --- 5. Tạo DataFrame cuối cùng ---\n",
    "# Chọn các cột cuối cùng và reset index để đảm bảo tính nhất quán\n",
    "final_df = master_df[['major_name', 'major_description', 'university_name', 'country', 'university_score']]\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "print(\"\\n🎉 Dữ liệu đã sẵn sàng cho Bước 2!\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"5 dòng dữ liệu đầu tiên:\")\n",
    "print(final_df.head())\n",
    "print(f\"\\nKích thước dữ liệu cuối cùng: {final_df.shape[0]} dòng và {final_df.shape[1]} cột.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f89e1ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T14:53:13.721347Z",
     "iopub.status.busy": "2025-10-17T14:53:13.720892Z",
     "iopub.status.idle": "2025-10-17T14:53:23.950313Z",
     "shell.execute_reply": "2025-10-17T14:53:23.949280Z"
    },
    "papermill": {
     "duration": 10.233952,
     "end_time": "2025-10-17T14:53:23.952021",
     "exception": false,
     "start_time": "2025-10-17T14:53:13.718069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\r\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\r\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.8.3)\r\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\r\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\r\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\r\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\r\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\r\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\r\n",
      "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\r\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\r\n",
      "Building wheels for collected packages: googletrans\r\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=e841943341b96e0c716e7be46bbd96bd9aeaf5cf6803069dcc65b51f1afe7e06\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\r\n",
      "Successfully built googletrans\r\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\r\n",
      "  Attempting uninstall: hyperframe\r\n",
      "    Found existing installation: hyperframe 6.1.0\r\n",
      "    Uninstalling hyperframe-6.1.0:\r\n",
      "      Successfully uninstalled hyperframe-6.1.0\r\n",
      "  Attempting uninstall: hpack\r\n",
      "    Found existing installation: hpack 4.1.0\r\n",
      "    Uninstalling hpack-4.1.0:\r\n",
      "      Successfully uninstalled hpack-4.1.0\r\n",
      "  Attempting uninstall: h11\r\n",
      "    Found existing installation: h11 0.16.0\r\n",
      "    Uninstalling h11-0.16.0:\r\n",
      "      Successfully uninstalled h11-0.16.0\r\n",
      "  Attempting uninstall: chardet\r\n",
      "    Found existing installation: chardet 5.2.0\r\n",
      "    Uninstalling chardet-5.2.0:\r\n",
      "      Successfully uninstalled chardet-5.2.0\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.10\r\n",
      "    Uninstalling idna-3.10:\r\n",
      "      Successfully uninstalled idna-3.10\r\n",
      "  Attempting uninstall: h2\r\n",
      "    Found existing installation: h2 4.3.0\r\n",
      "    Uninstalling h2-4.3.0:\r\n",
      "      Successfully uninstalled h2-4.3.0\r\n",
      "  Attempting uninstall: httpcore\r\n",
      "    Found existing installation: httpcore 1.0.9\r\n",
      "    Uninstalling httpcore-1.0.9:\r\n",
      "      Successfully uninstalled httpcore-1.0.9\r\n",
      "  Attempting uninstall: httpx\r\n",
      "    Found existing installation: httpx 0.28.1\r\n",
      "    Uninstalling httpx-0.28.1:\r\n",
      "      Successfully uninstalled httpx-0.28.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "huggingface-hub 1.0.0rc2 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "google-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "mcp 1.15.0 requires httpx>=0.27.1, but you have httpx 0.13.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "gradio-client 1.11.0 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "tokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "gradio 5.38.1 requires httpx<1.0,>=0.24.1, but you have httpx 0.13.3 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "google-genai 1.27.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.13.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "openai 1.97.1 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\r\n",
      "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.13.3 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "langsmith 0.4.8 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\r\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt thư viện googletrans phiên bản ổn định\n",
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7be3fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T14:53:23.962906Z",
     "iopub.status.busy": "2025-10-17T14:53:23.962621Z",
     "iopub.status.idle": "2025-10-17T14:53:25.682767Z",
     "shell.execute_reply": "2025-10-17T14:53:25.681674Z"
    },
    "papermill": {
     "duration": 1.727412,
     "end_time": "2025-10-17T14:53:25.684194",
     "exception": false,
     "start_time": "2025-10-17T14:53:23.956782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo xong ma trận vector cho các ngành học.\n",
      "Kích thước ma trận: (1084, 306)\n",
      "\n",
      "Đã nâng cấp bộ máy gợi ý với tính năng dịch tự động!\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết, thêm Translator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from googletrans import Translator\n",
    "\n",
    "# ===================================================================\n",
    "# PHẦN 1: XÂY DỰNG MÔ HÌNH ML (Không thay đổi)\n",
    "# ===================================================================\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "major_vectors = vectorizer.fit_transform(final_df['major_description'])\n",
    "print(\"Đã tạo xong ma trận vector cho các ngành học.\")\n",
    "print(\"Kích thước ma trận:\", major_vectors.shape)\n",
    "\n",
    "# Khởi tạo đối tượng Translator để tái sử dụng\n",
    "translator = Translator()\n",
    "\n",
    "# ===================================================================\n",
    "# PHẦN 2: VIẾT CÁC HÀM GỢI Ý (Cập nhật)\n",
    "# ===================================================================\n",
    "\n",
    "# HÀM 1: LỌC THEO QUY TẮC (Không thay đổi)\n",
    "def filter_by_rules(df, min_uni_score=60):\n",
    "    eligible_majors = df[df['university_score'] >= min_uni_score].copy()\n",
    "    print(f\"\\nĐang lọc... Tìm thấy {len(eligible_majors)} ngành học từ các trường có điểm >= {min_uni_score}\")\n",
    "    return eligible_majors\n",
    "\n",
    "# HÀM 2: XẾP HẠNG THEO SỞ THÍCH (Không thay đổi)\n",
    "def rank_by_interest(df, user_interest, vectorizer_model, major_vectors_matrix):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    user_vector = vectorizer_model.transform([user_interest])\n",
    "    filtered_indices = df.index\n",
    "    similarity_scores = cosine_similarity(user_vector, major_vectors_matrix[filtered_indices])\n",
    "    df['similarity'] = similarity_scores[0]\n",
    "    return df.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "\n",
    "# HÀM 3: HÀM TỔNG HỢP (✅ ĐÃ NÂNG CẤP VỚI TÍNH NĂNG DỊCH)\n",
    "def get_recommendations(user_score_input, user_interest_input, top_n=5):\n",
    "    \"\"\"\n",
    "    Kết hợp cả hai bước lọc và xếp hạng để đưa ra gợi ý.\n",
    "    Tự động dịch sở thích từ tiếng Việt sang tiếng Anh.\n",
    "    \"\"\"\n",
    "    # Bước A: Dịch sở thích của người dùng\n",
    "    print(f\"\\nSở thích của bạn: '{user_interest_input}'\")\n",
    "    translated_interest = translator.translate(user_interest_input, src='vi', dest='en').text\n",
    "    print(f\"---> Đã dịch sang tiếng Anh: '{translated_interest}'\")\n",
    "\n",
    "    # Bước B: Lọc theo quy tắc cứng (điểm số)\n",
    "    filtered_majors = filter_by_rules(final_df, min_uni_score=user_score_input)\n",
    "\n",
    "    # Bước C: Xếp hạng các kết quả đã lọc bằng sở thích đã được dịch\n",
    "    ranked_recommendations = rank_by_interest(\n",
    "        filtered_majors,\n",
    "        translated_interest,  # Sử dụng văn bản đã dịch\n",
    "        vectorizer,\n",
    "        major_vectors\n",
    "    )\n",
    "\n",
    "    # Trả về top N kết quả tốt nhất\n",
    "    return ranked_recommendations.head(top_n)\n",
    "\n",
    "print(\"\\nĐã nâng cấp bộ máy gợi ý với tính năng dịch tự động!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43dd79a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T14:53:25.694888Z",
     "iopub.status.busy": "2025-10-17T14:53:25.694434Z",
     "iopub.status.idle": "2025-10-17T14:53:26.592775Z",
     "shell.execute_reply": "2025-10-17T14:53:26.591662Z"
    },
    "papermill": {
     "duration": 0.905545,
     "end_time": "2025-10-17T14:53:26.594350",
     "exception": false,
     "start_time": "2025-10-17T14:53:25.688805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sở thích của bạn: 'Mình thích làm việc với dữ liệu, tìm kiếm quy luật, và dùng Python với SQL để xây dựng các mô hình học máy.'\n",
      "---> Đã dịch sang tiếng Anh: 'I like working with data, finding patterns, and using Python and SQL to build machine learning models.'\n",
      "\n",
      "Đang lọc... Tìm thấy 196 ngành học từ các trường có điểm >= 70\n",
      "\n",
      "\n",
      "================ KẾT QUẢ GỢI Ý (ĐÃ ĐA DẠNG HÓA) ================\n",
      "🎓 Ngành: Application of AI, InsurTech, and Real Estate Technology\n",
      "🏫 Trường: University Of Pennsylvania (USA)\n",
      "✨ Mức độ phù hợp sở thích: 0.44\n",
      "------------------------------\n",
      "🎓 Ngành: Data Science Capstone\n",
      "🏫 Trường: Johns Hopkins University (USA)\n",
      "✨ Mức độ phù hợp sở thích: 0.43\n",
      "------------------------------\n",
      "🎓 Ngành: Fundamentals of Machine Learning for Healthcare\n",
      "🏫 Trường: Stanford University (USA)\n",
      "✨ Mức độ phù hợp sở thích: 0.37\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# HÀM MỚI: ĐA DẠNG HÓA KẾT QUẢ\n",
    "# ===================================================================\n",
    "def diversify_recommendations(recommendations_df, top_n=5):\n",
    "    \"\"\"\n",
    "    Từ một danh sách gợi ý, chỉ giữ lại gợi ý tốt nhất (điểm similarity cao nhất)\n",
    "    của mỗi trường đại học để kết quả không bị trùng lặp.\n",
    "    \"\"\"\n",
    "    # Sắp xếp lại một lần nữa để đảm bảo hàng có điểm cao nhất ở trên cùng\n",
    "    recommendations_df = recommendations_df.sort_values(by='similarity', ascending=False)\n",
    "    \n",
    "    # Xóa các dòng bị trùng lặp 'university_name', chỉ giữ lại dòng ĐẦU TIÊN (có điểm cao nhất)\n",
    "    diversified_df = recommendations_df.drop_duplicates(subset=['university_name'], keep='first')\n",
    "    \n",
    "    return diversified_df.head(top_n)\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# PHẦN 1: NHẬP THÔNG TIN CỦA BẠN (Không thay đổi)\n",
    "# ===================================================================\n",
    "my_score = 70\n",
    "my_interest = \"Mình thích làm việc với dữ liệu, tìm kiếm quy luật, và dùng Python với SQL để xây dựng các mô hình học máy.\"\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# PHẦN 2: GỌI AI AGENT VÀ XỬ LÝ KẾT QUẢ (✅ ĐÃ NÂNG CẤP)\n",
    "# ===================================================================\n",
    "\n",
    "# Bước A: Lấy một danh sách gợi ý lớn hơn (ví dụ: top 20) để có nhiều lựa chọn\n",
    "initial_recommendations = get_recommendations(my_score, my_interest, top_n=20)\n",
    "\n",
    "# Bước B: Dùng hàm mới để lọc và đa dạng hóa kết quả, chỉ lấy top 5 cuối cùng\n",
    "final_recommendations = diversify_recommendations(initial_recommendations, top_n=5)\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# PHẦN 3: IN KẾT QUẢ (Không thay đổi)\n",
    "# ===================================================================\n",
    "print(\"\\n\\n================ KẾT QUẢ GỢI Ý (ĐÃ ĐA DẠNG HÓA) ================\")\n",
    "if final_recommendations.empty:\n",
    "    print(\"Rất tiếc, không tìm thấy ngành học nào phù hợp với yêu cầu của bạn.\")\n",
    "else:\n",
    "    for index, row in final_recommendations.iterrows():\n",
    "        print(f\"🎓 Ngành: {row['major_name']}\")\n",
    "        print(f\"🏫 Trường: {row['university_name'].title()} ({row['country']})\")\n",
    "        print(f\"✨ Mức độ phù hợp sở thích: {row['similarity']:.2f}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f3ee64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-17T14:53:26.605370Z",
     "iopub.status.busy": "2025-10-17T14:53:26.605068Z",
     "iopub.status.idle": "2025-10-17T14:53:26.636829Z",
     "shell.execute_reply": "2025-10-17T14:53:26.635637Z"
    },
    "papermill": {
     "duration": 0.038761,
     "end_time": "2025-10-17T14:53:26.638323",
     "exception": false,
     "start_time": "2025-10-17T14:53:26.599562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lưu thành công 2 tệp: 'tfidf_vectorizer.pkl' và 'final_majors_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Lưu lại mô hình TF-IDF đã được huấn luyện\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# Lưu lại DataFrame đã được làm sạch cuối cùng\n",
    "final_df.to_csv('final_majors_data.csv', index=False)\n",
    "\n",
    "print(\"✅ Đã lưu thành công 2 tệp: 'tfidf_vectorizer.pkl' và 'final_majors_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 27,
     "sourceId": 792993,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2709508,
     "sourceId": 4671879,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4289048,
     "sourceId": 7585863,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.813902,
   "end_time": "2025-10-17T14:53:27.362532",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-17T14:53:07.548630",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
